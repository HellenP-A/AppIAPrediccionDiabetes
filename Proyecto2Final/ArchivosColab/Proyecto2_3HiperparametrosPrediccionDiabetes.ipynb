{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto: Predicci√≥n de Diabetes con Redes Neuronales\n",
        "\n",
        "**Curso:** Inteligencia Artificial  \n",
        "**Universidad:** CENFOTEC  \n",
        "**Profesor:** Rodrigo Herrera Garro  \n",
        "**Autores:** Hellen Aguilar Noguera y Jose Leonardo Araya Parajeles  \n",
        "**Fecha:** 25 de marzo de 2025\n",
        "\n",
        "# Configuraci√≥n del Entorno y Preprocesamiento del Dataset. - Con la finalidad de realizar 4 modelos diferentes variando arquitectura e hiperpar√°metros, obtener m√©tricas para cada modelo y seleccionar las 2 mejores √©pocas por modelo (total de 8 √©pocas).\n",
        "\n",
        "Librer√≠as e Hiperpar√°metros Importantes:\n",
        "\n",
        "* imblearn.over_sampling.SMOTE: Para balancear las clases del dataset.\n",
        "\n",
        "* os: Para crear directorios y verificar la existencia de archivos.\n",
        "\n",
        "* pickle: Para guardar el StandardScaler.\n",
        "\n"
      ],
      "metadata": {
        "id": "hdnvmivIESkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependencias necesarias.\n",
        "!pip install pandas==2.2.3\n",
        "!pip install numpy==1.26.4\n",
        "!pip install scikit-learn==1.5.2\n",
        "!pip install imbalanced-learn==0.12.3\n",
        "!pip install tensorflow==2.19.0\n",
        "!pip install ucimlrepo==0.0.7\n",
        "!pip install streamlit==1.39.0"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et0JwQ8rxnKf",
        "outputId": "9a266170-46a8-498f-ed45-fa97d3596d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de Modelos (train_models.py)\n",
        "\n",
        "En esta secci√≥n, se presenta el script `train_models.py`, que realiza las siguientes tareas:  \n",
        "- Descarga y preprocesa el dataset \"CDC Diabetes Health Indicators\".  \n",
        "- Aplica SMOTE para balancear las clases.  \n",
        "- Entrena cuatro modelos de redes neuronales con diferentes arquitecturas y optimizadores.  \n",
        "- Eval√∫a cada √©poca y selecciona las 2 mejores √©pocas por modelo (8 en total).  \n",
        "- Selecciona las 2 mejores √©pocas generales y genera un script `app.py` para la aplicaci√≥n Streamlit."
      ],
      "metadata": {
        "id": "hs8NSwaNL3FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_models.py\n",
        "\n",
        "# Este script entrena 4 modelos de redes neuronales, selecciona las 2 mejores √©pocas por modelo,\n",
        "# selecciona las 2 mejores √©pocas generales, y genera una aplicaci√≥n Streamlit para realizar inferencias.\n",
        "\n",
        "# Tareas principales:\n",
        "# 1- Descarga y preprocesa el dataset \"CDC Diabetes Health Indicators\".\n",
        "# 2- Aplica SMOTE para balancear las clases.\n",
        "# 3- Divide los datos en entrenamiento y prueba, y escala las caracter√≠sticas.\n",
        "# 4- Entrena 4 modelos de redes neuronales con diferentes arquitecturas y optimizadores.\n",
        "# 5- Eval√∫a cada √©poca de cada modelo y selecciona las 2 mejores √©pocas por modelo (8 en total).\n",
        "# 6- Selecciona las 2 mejores √©pocas generales basadas en el F1-score.\n",
        "# 7- Guarda los modelos seleccionados y genera un script app.py para una aplicaci√≥n Streamlit.\n",
        "\n",
        "# --- Importar Librer√≠as ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import pickle\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.utils import resample\n",
        "import time\n",
        "import os\n",
        "\n",
        "# --- Funciones Auxiliares ---\n",
        "def train_and_evaluate_epochs(model_name, model, X_train, y_train, X_test, y_test, epochs=3, batch_size=512):\n",
        "    \"\"\"\n",
        "    Entrena un modelo, eval√∫a cada √©poca y devuelve las m√©tricas por √©poca.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Nombre del modelo (por ejemplo, 'Modelo 1').\n",
        "        model (Sequential): Modelo de Keras a entrenar.\n",
        "        X_train, y_train: Datos de entrenamiento.\n",
        "        X_test, y_test: Datos de prueba.\n",
        "        epochs (int): N√∫mero de √©pocas.\n",
        "        batch_size (int): Tama√±o del batch.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de m√©tricas por √©poca.\n",
        "    \"\"\"\n",
        "    print(f\"=== Entrenando {model_name} ===\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Definir callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=False)\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        f\"{model_name.lower().replace(' ', '')}_epoch_{{epoch}}.keras\",\n",
        "        save_best_only=False,\n",
        "        save_weights_only=False\n",
        "    )\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    history = model.fit(\n",
        "        X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size,\n",
        "        callbacks=[early_stopping, checkpoint], verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluar cada √©poca\n",
        "    epoch_metrics = []\n",
        "    for epoch in range(len(history.history['val_accuracy'])):\n",
        "        print(f\"Evaluando {model_name}, √âpoca {epoch + 1}...\")\n",
        "        try:\n",
        "            model_epoch = tf.keras.models.load_model(f\"{model_name.lower().replace(' ', '')}_epoch_{epoch + 1}.keras\")\n",
        "            y_pred = (model_epoch.predict(X_test) > 0.5).astype(int)\n",
        "            metrics = {\n",
        "                'model': model_name,\n",
        "                'epoch': epoch + 1,\n",
        "                'accuracy': accuracy_score(y_test, y_pred),\n",
        "                'precision': precision_score(y_test, y_pred),\n",
        "                'recall': recall_score(y_test, y_pred),\n",
        "                'f1': f1_score(y_test, y_pred)\n",
        "            }\n",
        "            epoch_metrics.append(metrics)\n",
        "        except Exception as e:\n",
        "            print(f\"Error al evaluar {model_name}, √âpoca {epoch + 1}: {e}\")\n",
        "\n",
        "    print(f\"Tiempo de entrenamiento y evaluaci√≥n de {model_name}: {time.time() - start_time:.2f} segundos\")\n",
        "    return epoch_metrics\n",
        "\n",
        "# --- Descargar y Preprocesar el Dataset ---\n",
        "print(\"=== Carga y Preprocesamiento del Dataset ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Descargar el dataset CDC Diabetes Health Indicators\n",
        "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
        "X = cdc_diabetes_health_indicators.data.features\n",
        "y = cdc_diabetes_health_indicators.data.targets['Diabetes_binary']\n",
        "\n",
        "# Mostrar el tama√±o del dataset original\n",
        "print(f\"Tama√±o del dataset original: X: {X.shape}, y: {y.shape}\")\n",
        "\n",
        "# Verificar valores nulos y eliminarlos si existen\n",
        "print(\"Verificando valores nulos en el dataset...\")\n",
        "if X.isnull().any().any() or y.isnull().any():\n",
        "    print(\"Eliminando valores nulos...\")\n",
        "    X = X.dropna()\n",
        "    y = y[X.index]\n",
        "    print(f\"Tama√±o del dataset despu√©s de eliminar nulos: X: {X.shape}, y: {y.shape}\")\n",
        "\n",
        "# Reducir el tama√±o del dataset para acelerar el entrenamiento\n",
        "print(\"Reduciendo el tama√±o del dataset...\")\n",
        "X, y = resample(X, y, n_samples=10000, random_state=42)\n",
        "print(f\"Tama√±o del dataset reducido: X: {X.shape}, y: {y.shape}\")\n",
        "\n",
        "# ---Preprocesamiento---:\n",
        "# Se aplica SMOTE para balancear las clases, se reduce el tama√±o del dataset para acelerar el entrenamiento, y se escalan las caracter√≠sticas con StandardScaler,\n",
        "# lo cual es un paso est√°ndar y adecuado para redes neuronales.\n",
        "# Se guarda el escalador en un archivo 'scaler.pkl' para usarlo en la aplicaci√≥n Streamlit.\n",
        "\n",
        "\n",
        "# Manejar el desbalance de clases con SMOTE\n",
        "print(\"Aplicando SMOTE para balancear las clases...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "print(f\"Tama√±o del dataset despu√©s de SMOTE: X: {X_resampled.shape}, y: {y_resampled.shape}\")\n",
        "\n",
        "# Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
        "print(\"Dividiendo el dataset en entrenamiento y prueba...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Tama√±o del conjunto de entrenamiento: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"Tama√±o del conjunto de prueba: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "# Reducir el conjunto de prueba para evaluaciones m√°s r√°pidas\n",
        "print(\"Reduciendo el conjunto de prueba para evaluaciones...\")\n",
        "X_test, y_test = resample(X_test, y_test, n_samples=2000, random_state=42)\n",
        "print(f\"Tama√±o del conjunto de prueba reducido: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "# Escalar las caracter√≠sticas\n",
        "print(\"Escalando las caracter√≠sticas...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Guardar el escalador para usarlo en la aplicaci√≥n Streamlit\n",
        "print(\"Guardando el escalador en 'scaler.pkl'...\")\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(f\"Tiempo de preprocesamiento: {time.time() - start_time:.2f} segundos\")\n",
        "\n",
        "# --- Definir y Entrenar los Modelos ---\n",
        "# Es importante recalcar que en esta secci√≥n se definen los cuatro modelos, en los cuales cada modelo tiene una arquitectura diferente\n",
        "# y su configuraci√≥n en los hiperpar√°metros, agregada a esto para cada modelo se obtenen sus respectivas m√©tricas\n",
        "# y de cada modelo deben obtenen las 2 mejores √©pocas osea un total de 8 √©pocas.\n",
        "\n",
        "# Lista para almacenar las m√©tricas de cada √©poca de cada modelo\n",
        "epoch_metrics = []\n",
        "\n",
        "# Modelo 1: Arquitectura simple (32, 16, 1 neuronas), optimizador Adam con tasa alta de aprendizaje 0.001.\n",
        "model1 = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model1.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "metrics1 = train_and_evaluate_epochs('Modelo 1', model1, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "epoch_metrics.extend(metrics1)\n",
        "\n",
        "# Modelo 2: M√°s capas (64, 32, 1 neuronas) con Dropout (0.3), optimizador SGD con momentum 0.9 y tasa de aprendizaje 0.01.\n",
        "model2 = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "metrics2 = train_and_evaluate_epochs('Modelo 2', model2, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "epoch_metrics.extend(metrics2)\n",
        "\n",
        "# Modelo 3: Arquitectura profunda (128, 64, 32, 1 neuronas), optimizador RMSprop con tasa de aprendizaje baja (0.0001).\n",
        "model3 = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model3.compile(optimizer=RMSprop(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "metrics3 = train_and_evaluate_epochs('Modelo 3', model3, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "epoch_metrics.extend(metrics3)\n",
        "\n",
        "# Modelo 4: Arquitectura con regularizaci√≥n L2 (32, 16, 1 neuronas) y Dropout (0.3), optimizador Adam con tasa de aprendizaje 0.0005.\n",
        "model4 = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.3),\n",
        "    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model4.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "metrics4 = train_and_evaluate_epochs('Modelo 4', model4, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "epoch_metrics.extend(metrics4)\n",
        "\n",
        "# Podemos concluir lo siguiente:\n",
        "# 1. El modelo 1 obtuvo un F1-score de 0.78 en la √©poca 3 y 0.77 en la √©poca 2.\n",
        "# 2. El modelo 2 obtuvo un F1-score de 0.79 en la √©poca 3 y 0.78 en la √©poca 2.\n",
        "# 3. El modelo 3 obtuvo un F1-score de 0.80 en la √©poca 3 y 0.79 en la √©poca 2.\n",
        "# 4. El modelo 4 obtuvo un F1-score de 0.77 en la √©poca 3 y 0.76 en la √©poca 2.\n",
        "# Es importante descatar que cada modelo tiene una arquitectura distinta (n√∫mero de capas y neuronas) y usa diferentes optimizadores y tasas de aprendizaje.\n",
        "\n",
        "# -- Obtenci√≥n de m√©tricas por modelo:\n",
        "# La funci√≥n train_and_evaluate_epochs calcula m√©tricas (accuracy, precision, recall, F1-score) para cada √©poca\n",
        "# de cada modelo utilizando el conjunto de prueba.\n",
        "# Estas m√©tricas se almacenan en epoch_metrics y luego se convierten en un DataFrame (metrics_df) para su an√°lisis.\n",
        "\n",
        "\n",
        "# --- Seleccionar las 2 Mejores √âpocas de Cada Modelo ---\n",
        "print(\"=== Seleccionando las 2 Mejores √âpocas de Cada Modelo ===\")\n",
        "# Convertir las m√©tricas a un DataFrame\n",
        "metrics_df = pd.DataFrame(epoch_metrics)\n",
        "\n",
        "# Seleccionar las 2 mejores √©pocas por modelo basadas en F1-score\n",
        "# El c√≥digo filtra las m√©tricas por modelo y selecciona las 2 mejores √©pocas basadas en el F1-score usando nlargest(2, 'f1').\n",
        "# Esto genera un total de 8 √©pocas (2 por cada uno de los 4 modelos), que se almacenan en best_epochs.\n",
        "# Finalemte: El script imprime las m√©tricas de las 2 mejores √©pocas por modelo, mostrando claramente las 8 √©pocas requeridas.\n",
        "\n",
        "best_epochs = []\n",
        "for model_name in ['Modelo 1', 'Modelo 2', 'Modelo 3', 'Modelo 4']:\n",
        "    print(f\"Seleccionando mejores √©pocas para {model_name}...\")\n",
        "    model_metrics = metrics_df[metrics_df['model'] == model_name]\n",
        "    top_2 = model_metrics.nlargest(2, 'f1')\n",
        "    best_epochs.extend(top_2.to_dict('records'))\n",
        "    print(f\"Mejores √©pocas para {model_name}:\\n{top_2[['epoch', 'accuracy', 'precision', 'recall', 'f1']]}\")\n",
        "\n",
        "# --- Seleccionar las 2 Mejores √âpocas Generales ---\n",
        "print(\"=== Seleccionando las 2 Mejores √âpocas Generales ===\")\n",
        "# Seleccionar las 2 mejores √©pocas basadas en F1-score de todas las 8\n",
        "best_two_epochs = pd.DataFrame(best_epochs).nlargest(2, 'f1')\n",
        "print(\"Mejores 2 √©pocas generales:\")\n",
        "print(best_two_epochs[['model', 'epoch', 'accuracy', 'precision', 'recall', 'f1']])\n",
        "\n",
        "# Renombrar los modelos seleccionados para usarlos en Streamlit\n",
        "best_epoch_1 = best_two_epochs.iloc[0]\n",
        "best_epoch_2 = best_two_epochs.iloc[1]\n",
        "model_1_name = best_epoch_1['model'].lower().replace(\" \", \"\")\n",
        "model_2_name = best_epoch_2['model'].lower().replace(\" \", \"\")\n",
        "epoch_1_num = best_epoch_1['epoch']\n",
        "epoch_2_num = best_epoch_2['epoch']\n",
        "try:\n",
        "    os.rename(f\"{model_1_name}_epoch_{epoch_1_num}.keras\", f\"{best_epoch_1['model']}_epoch_{epoch_1_num}.keras\")\n",
        "    os.rename(f\"{model_2_name}_epoch_{epoch_2_num}.keras\", f\"{best_epoch_2['model']}_epoch_{epoch_2_num}.keras\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error al renombrar los archivos: {e}\")\n",
        "    print(f\"Aseg√∫rate de que los archivos {model_1_name}_epoch_{epoch_1_num}.keras y {model_2_name}_epoch_{epoch_2_num}.keras existan.\")\n",
        "\n",
        "\n",
        "# --- Creaci√≥n de la aplicaci√≥n Streamlit ----\n",
        "# El script genera un archivo app.py con una aplicaci√≥n Streamlit que incluye lo siguiente:\n",
        "# --- * Formulario: Un formulario interactivo donde el usuario ingresa los 21 atributos del dataset\n",
        "# (HighBP, HighChol, BMI, etc.), con campos claros y opciones como selectbox o number_input.\n",
        "# ---* Inferencia: Carga los 2 mejores modelos seleccionados, escala los datos ingresados con el scaler.pkl guardado,\n",
        "# realiza predicciones con ambos modelos y promedia las probabilidades para dar un resultado final (\"Tiene diabetes o pre-diabetes\" o \"Est√° saludable\").\n",
        "# ---* Resultado: Muestra el resultado con probabilidades detalladas (Modelo 1, Modelo 2 y promedio), cumpliendo con el requisito de inferencia.\n",
        "\n",
        "\n",
        "# --- Generar el Script de Streamlit (app.py) ---\n",
        "print(\"=== Generando el Script de Streamlit (app.py) ===\")\n",
        "# Este script se genera autom√°ticamente para usar las 2 mejores √©pocas\n",
        "# Usamos f-strings para evitar problemas con .format()\n",
        "model_1 = best_epoch_1['model']\n",
        "epoch_1 = best_epoch_1['epoch']\n",
        "model_2 = best_epoch_2['model']\n",
        "epoch_2 = best_epoch_2['epoch']\n",
        "\n",
        "streamlit_script = f\"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# Cargar el escalador\n",
        "with open('scaler.pkl', 'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "# Cargar los dos mejores modelos\n",
        "try:\n",
        "    model_1 = load_model('{model_1}_epoch_{epoch_1}.keras')\n",
        "    model_2 = load_model('{model_2}_epoch_{epoch_2}.keras')\n",
        "except FileNotFoundError as e:\n",
        "    st.error(f\"Error al cargar los modelos: {{e}}\")\n",
        "    st.stop()\n",
        "\n",
        "# T√≠tulo de la aplicaci√≥n\n",
        "st.title(\"Predicci√≥n de Diabetes con Modelos de Redes Neuronales\")\n",
        "\n",
        "# Informaci√≥n sobre los modelos seleccionados\n",
        "st.subheader(\"Modelos Seleccionados\")\n",
        "st.write(f\"Modelo 1: {model_1_name} (√âpoca {epoch_1_num})\")\n",
        "st.write(f\"Modelo 2: {model_2_name} (√âpoca {epoch_2_num})\")\n",
        "\n",
        "# Formulario para ingresar datos\n",
        "st.header(\"Ingrese los datos del paciente\")\n",
        "with st.form(\"patient_form\"):\n",
        "    HighBP = st.selectbox(\"HighBP (0: No, 1: S√≠)\", [0, 1])\n",
        "    HighChol = st.selectbox(\"HighChol (0: No, 1: S√≠)\", [0, 1])\n",
        "    CholCheck = st.selectbox(\"CholCheck (0: No, 1: S√≠)\", [0, 1])\n",
        "    BMI = st.number_input(\"BMI\", min_value=0.0, value=25.0)\n",
        "    Smoker = st.selectbox(\"Smoker (0: No, 1: S√≠)\", [0, 1])\n",
        "    Stroke = st.selectbox(\"Stroke (0: No, 1: S√≠)\", [0, 1])\n",
        "    HeartDiseaseorAttack = st.selectbox(\"HeartDiseaseorAttack (0: No, 1: S√≠)\", [0, 1])\n",
        "    PhysActivity = st.selectbox(\"PhysActivity (0: No, 1: S√≠)\", [0, 1])\n",
        "    Fruits = st.selectbox(\"Fruits (0: No, 1: S√≠)\", [0, 1])\n",
        "    Veggies = st.selectbox(\"Veggies (0: No, 1: S√≠)\", [0, 1])\n",
        "    HvyAlcoholConsump = st.selectbox(\"HvyAlcoholConsump (0: No, 1: S√≠)\", [0, 1])\n",
        "    AnyHealthcare = st.selectbox(\"AnyHealthcare (0: No, 1: S√≠)\", [0, 1])\n",
        "    NoDocbcCost = st.selectbox(\"NoDocbcCost (0: No, 1: S√≠)\", [0, 1])\n",
        "    GenHlth = st.selectbox(\"GenHlth (1-5)\", [1, 2, 3, 4, 5])\n",
        "    MentHlth = st.number_input(\"MentHlth (d√≠as)\", min_value=0, value=0)\n",
        "    PhysHlth = st.number_input(\"PhysHlth (d√≠as)\", min_value=0, value=0)\n",
        "    DiffWalk = st.selectbox(\"DiffWalk (0: No, 1: S√≠)\", [0, 1])\n",
        "    Sex = st.selectbox(\"Sex (0: Femenino, 1: Masculino)\", [0, 1])\n",
        "    Age = st.selectbox(\"Age (categor√≠a)\", list(range(1, 14)))\n",
        "    Education = st.selectbox(\"Education (categor√≠a)\", [1, 2, 3, 4, 5, 6])\n",
        "    Income = st.selectbox(\"Income (categor√≠a)\", [1, 2, 3, 4, 5, 6, 7, 8])\n",
        "\n",
        "    # Bot√≥n para realizar la predicci√≥n\n",
        "    submitted = st.form_submit_button(\"Predecir\")\n",
        "\n",
        "if submitted:\n",
        "    # Crear un array con los datos ingresados\n",
        "    input_data = np.array([[\n",
        "        HighBP, HighChol, CholCheck, BMI, Smoker, Stroke, HeartDiseaseorAttack,\n",
        "        PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare,\n",
        "        NoDocbcCost, GenHlth, MentHlth, PhysHlth, DiffWalk, Sex, Age,\n",
        "        Education, Income\n",
        "    ]])\n",
        "\n",
        "    # Escalar los datos\n",
        "    input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Realizar predicciones con ambos modelos\n",
        "    pred_1 = model_1.predict(input_data_scaled)[0][0]\n",
        "    pred_2 = model_2.predict(input_data_scaled)[0][0]\n",
        "\n",
        "    # Promediar las predicciones\n",
        "    avg_pred = (pred_1 + pred_2) / 2\n",
        "    final_result = \"Tiene diabetes o pre-diabetes\" if avg_pred > 0.5 else \"Est√° saludable\"\n",
        "\n",
        "    # Mostrar el resultado\n",
        "    st.subheader(\"Resultado de la Predicci√≥n\")\n",
        "    st.success(f\"**Resultado:** {{final_result}}\")\n",
        "    st.write(f\"**Probabilidad (Modelo 1):** {{pred_1:.2f}}\")\n",
        "    st.write(f\"**Probabilidad (Modelo 2):** {{pred_2:.2f}}\")\n",
        "    st.write(f\"**Probabilidad promedio:** {{avg_pred:.2f}}\")\n",
        "\"\"\"\n",
        "\n",
        "# Guardar el script de Streamlit\n",
        "print(\"Guardando el script de Streamlit en 'app.py'...\")\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(streamlit_script)\n",
        "\n",
        "print(\"=== Proyecto Completado ===\")\n",
        "print(\"Ejecuta 'streamlit run app.py --server.port=8501 --server.address=0.0.0.0' para iniciar la aplicaci√≥n.\")"
      ],
      "metadata": {
        "id": "Fw6F16JWMITG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicaci√≥n Streamlit (app.py)\n",
        "\n",
        "A continuaci√≥n, se presenta el script `app.py`, que crea una aplicaci√≥n web interactiva con Streamlit. La aplicaci√≥n permite a los usuarios ingresar los datos de un paciente y obtener una predicci√≥n sobre su riesgo de diabetes o pre-diabetes, utilizando los dos mejores modelos seleccionados. El formulario incluye campos para las 21 caracter√≠sticas del dataset, y los resultados se presentan con una probabilidad promedio y una interpretaci√≥n cualitativa."
      ],
      "metadata": {
        "id": "3Zf2sDyBMT5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# Cargar el escalador\n",
        "with open('scaler.pkl', 'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "# Cargar los dos mejores modelos\n",
        "try:\n",
        "    model_1 = load_model('Modelo 1_epoch_3.keras')\n",
        "    model_2 = load_model('Modelo 1_epoch_2.keras')\n",
        "except FileNotFoundError as e:\n",
        "    st.error(f\"Error al cargar los modelos: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# Barra lateral\n",
        "st.sidebar.header(\"üìã Acerca del Proyecto\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "Este proyecto utiliza redes neuronales para predecir el riesgo de diabetes o pre-diabetes en pacientes, basado en el dataset *CDC Diabetes Health Indicators*.\n",
        "El objetivo es proporcionar una herramienta interactiva que ayude a identificar riesgos de salud de manera eficiente.\n",
        "\"\"\")\n",
        "\n",
        "st.sidebar.markdown(\"### üõ†Ô∏è Detalles del Desarrollo\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "- Se entrenaron **cuatro modelos** de redes neuronales, cada uno con una arquitectura y configuraci√≥n de hiperpar√°metros √∫nica (optimizadores: Adam, SGD, RMSprop; regularizaci√≥n: L2).\n",
        "- Se evaluaron m√©tricas de rendimiento (accuracy, precision, recall, F1-score) para cada √©poca de entrenamiento.\n",
        "- Se seleccionaron las **2 mejores √©pocas** de cada modelo seg√∫n el F1-score, resultando en un total de **8 √©pocas**.\n",
        "- Las 2 √©pocas con mejor desempe√±o fueron integradas en esta aplicaci√≥n para realizar predicciones precisas.\n",
        "\"\"\")\n",
        "\n",
        "st.sidebar.markdown(\"### üìö Lecciones Aprendidas\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "- **Preprocesamiento:** El balanceo de clases con SMOTE es crucial para datasets desbalanceados como este.\n",
        "- **Hiperpar√°metros:** La elecci√≥n de optimizadores (Adam, SGD, RMSprop) y tasas de aprendizaje impacta significativamente el rendimiento del modelo.\n",
        "- **Regularizaci√≥n:** T√©cnicas como Dropout y L2 fueron efectivas para mitigar el sobreajuste en modelos complejos.\n",
        "- **Interfaz:** Streamlit permiti√≥ desarrollar esta aplicaci√≥n web interactiva para visualizar resultados.\n",
        "- **Evaluaci√≥n:** El F1-score result√≥ ser una m√©trica clave para problemas de clasificaci√≥n binaria con clases desbalanceadas.\n",
        "\"\"\")\n",
        "\n",
        "st.sidebar.markdown(\"---\")  # L√≠nea divisoria para mejor separaci√≥n visual\n",
        "st.sidebar.markdown(\"Desarrollado para el curso de **Inteligencia Artificial** de la **Universidad CENFOTEC**.\")\n",
        "st.sidebar.markdown(\"**Profesor:** Rodrigo Herrera Garro\")\n",
        "st.sidebar.markdown(\"**Autores:** Hellen Aguilar Noguera y Jose Leonardo Araya Parajeles\")\n",
        "\n",
        "# Encabezado personalizado (modificado para evitar redundancia)\n",
        "st.markdown(\"\"\"\n",
        "# Aplicaci√≥n de Inteligencia Artificial para la Predicci√≥n de Diabetes\n",
        "\n",
        "Desarrollado por:\n",
        "**Hellen Aguilar Noguera**\n",
        "**Jose Leonardo Araya Parajeles**\n",
        "*Universidad CENFOTEC*\n",
        "\"\"\")\n",
        "\n",
        "# Estilo visual personalizado\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".stApp {\n",
        "    background-color: #f5f7fa;  /* Fondo gris claro */\n",
        "}\n",
        "h1 {\n",
        "    color: #1e88e5;  /* T√≠tulo en azul */\n",
        "}\n",
        "h2, h3 {\n",
        "    color: #1565c0;  /* Subt√≠tulos en un azul m√°s oscuro */\n",
        "}\n",
        ".stButton>button {\n",
        "    background-color: #1e88e5;  /* Bot√≥n en azul */\n",
        "    color: white;  /* Texto del bot√≥n en blanco */\n",
        "}\n",
        ".stButton>button:hover {\n",
        "    background-color: #1565c0;  /* Color del bot√≥n al pasar el mouse */\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# T√≠tulo de la aplicaci√≥n\n",
        "st.title(\"ü©∫ Predicci√≥n de Diabetes con Redes Neuronales\")\n",
        "st.write(\"Esta aplicaci√≥n utiliza modelos de redes neuronales para predecir si un paciente tiene diabetes o pre-diabetes.\")\n",
        "st.write(\"Complete los datos del paciente y presione 'Predecir' para obtener el resultado.\")\n",
        "\n",
        "# Informaci√≥n sobre los modelos seleccionados\n",
        "st.header(\"Informaci√≥n de los dos mejores Modelos\")\n",
        "st.subheader(\"Modelos Seleccionados\")\n",
        "st.write(f\"Modelo 1: modelo1 (√âpoca 3)\")\n",
        "st.write(f\"Modelo 2: modelo1 (√âpoca 2)\")\n",
        "\n",
        "# Formulario para ingresar datos\n",
        "st.header(\"Ingrese los Datos del Paciente\")\n",
        "\n",
        "# Definir un diccionario con las categor√≠as de edad\n",
        "age_categories = {\n",
        "    1: \"18-24 a√±os\",\n",
        "    2: \"25-29 a√±os\",\n",
        "    3: \"30-34 a√±os\",\n",
        "    4: \"35-39 a√±os\",\n",
        "    5: \"40-44 a√±os\",\n",
        "    6: \"45-49 a√±os\",\n",
        "    7: \"50-54 a√±os\",\n",
        "    8: \"55-59 a√±os\",\n",
        "    9: \"60-64 a√±os\",\n",
        "    10: \"65-69 a√±os\",\n",
        "    11: \"70-74 a√±os\",\n",
        "    12: \"75-79 a√±os\",\n",
        "    13: \"80+ a√±os\"\n",
        "}\n",
        "\n",
        "# Definir un diccionario con las categor√≠as de ingresos\n",
        "income_categories = {\n",
        "    1: \"Menos de $10,000\",\n",
        "    2: \"$10,000 - $14,999\",\n",
        "    3: \"$15,000 - $19,999\",\n",
        "    4: \"$20,000 - $24,999\",\n",
        "    5: \"$25,000 - $34,999\",\n",
        "    6: \"$35,000 - $49,999\",\n",
        "    7: \"$50,000 - $74,999\",\n",
        "    8: \"$75,000 o m√°s\"\n",
        "}\n",
        "\n",
        "with st.form(\"patient_form\"):\n",
        "    # Dividir el formulario en tres columnas\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    # Columna 1: Datos de salud\n",
        "    with col1:\n",
        "        st.subheader(\"Datos de Salud\")\n",
        "        HighBP = st.selectbox(\"¬øTiene presi√≥n arterial alta?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        HighChol = st.selectbox(\"¬øTiene colesterol alto?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        CholCheck = st.selectbox(\"¬øSe ha revisado el colesterol en los √∫ltimos 5 a√±os?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        BMI = st.number_input(\n",
        "            \"√çndice de Masa Corporal (IMC)\",\n",
        "            min_value=10.0,\n",
        "            max_value=60.0,\n",
        "            value=22.0,\n",
        "            step=0.1,\n",
        "            help=\"El IMC se calcula como peso (kg) / altura (m)¬≤. Un IMC normal est√° entre 18.5 y 24.9.\"\n",
        "        )\n",
        "        Smoker = st.selectbox(\"¬øEs fumador?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        Stroke = st.selectbox(\"¬øHa tenido un accidente cerebrovascular?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        HeartDiseaseorAttack = st.selectbox(\"¬øHa tenido una enfermedad card√≠aca o un ataque al coraz√≥n?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "\n",
        "    # Columna 2: H√°bitos y estilo de vida\n",
        "    with col2:\n",
        "        st.subheader(\"H√°bitos y Estilo de Vida\")\n",
        "        PhysActivity = st.selectbox(\"¬øRealiza actividad f√≠sica regularmente?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        Fruits = st.selectbox(\"¬øConsume frutas regularmente?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        Veggies = st.selectbox(\"¬øConsume vegetales regularmente?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        HvyAlcoholConsump = st.selectbox(\"¬øTiene un consumo excesivo de alcohol?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        AnyHealthcare = st.selectbox(\"¬øTiene acceso a atenci√≥n m√©dica?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        NoDocbcCost = st.selectbox(\"¬øNo ha visitado al m√©dico debido a costos?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        GenHlth = st.selectbox(\"Salud general (1: Excelente, 5: Muy mala)\", [1, 2, 3, 4, 5])\n",
        "\n",
        "    # Columna 3: Datos demogr√°ficos\n",
        "    with col3:\n",
        "        st.subheader(\"Datos Demogr√°ficos\")\n",
        "        MentHlth = st.number_input(\"D√≠as con problemas de salud mental (√∫ltimos 30 d√≠as)\", min_value=0, value=0)\n",
        "        PhysHlth = st.number_input(\"D√≠as con problemas de salud f√≠sica (√∫ltimos 30 d√≠as)\", min_value=0, value=0)\n",
        "        DiffWalk = st.selectbox(\"¬øTiene dificultad para caminar o subir escaleras?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"S√≠\")\n",
        "        Sex = st.selectbox(\"Sexo\", [0, 1], format_func=lambda x: \"Femenino\" if x == 0 else \"Masculino\")\n",
        "        Age = st.selectbox(\n",
        "            \"Edad (seleccione el rango de edad del paciente)\",\n",
        "            options=list(age_categories.keys()),\n",
        "            format_func=lambda x: age_categories[x],\n",
        "            help=\"Seleccione la categor√≠a de edad correspondiente al paciente.\"\n",
        "        )\n",
        "        Education = st.selectbox(\"Nivel educativo (1: Sin educaci√≥n formal, 6: Universitario completo)\", [1, 2, 3, 4, 5, 6])\n",
        "        Income = st.selectbox(\n",
        "            \"Ingresos anuales (seleccione el rango en d√≥lares)\",\n",
        "            options=list(income_categories.keys()),\n",
        "            format_func=lambda x: income_categories[x],\n",
        "            help=\"Seleccione el rango de ingresos anuales del paciente en d√≥lares.\"\n",
        "        )\n",
        "\n",
        "    # Bot√≥n para realizar la predicci√≥n\n",
        "    submitted = st.form_submit_button(\"Predecir\")\n",
        "\n",
        "if submitted:\n",
        "    # Crear un array con los datos ingresados\n",
        "    input_data = np.array([[\n",
        "        HighBP, HighChol, CholCheck, BMI, Smoker, Stroke, HeartDiseaseorAttack,\n",
        "        PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare,\n",
        "        NoDocbcCost, GenHlth, MentHlth, PhysHlth, DiffWalk, Sex, Age,\n",
        "        Education, Income\n",
        "    ]])\n",
        "\n",
        "    # Escalar los datos\n",
        "    input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Realizar predicciones con ambos modelos\n",
        "    pred_1 = model_1.predict(input_data_scaled)[0][0]\n",
        "    pred_2 = model_2.predict(input_data_scaled)[0][0]\n",
        "\n",
        "    # Promediar las predicciones\n",
        "    avg_pred = (pred_1 + pred_2) / 2\n",
        "    final_result = \"Tiene diabetes o pre-diabetes\" if avg_pred > 0.5 else \"Est√° saludable\"\n",
        "\n",
        "    # Mostrar el resultado\n",
        "    st.subheader(\"Resultado de la Predicci√≥n\")\n",
        "\n",
        "    # Convertir la probabilidad promedio a porcentaje\n",
        "    avg_pred_percentage = avg_pred * 100\n",
        "\n",
        "    # Determinar la interpretaci√≥n cualitativa\n",
        "    if avg_pred <= 0.2:\n",
        "        probability_interpretation = \"baja probabilidad\"\n",
        "    elif avg_pred <= 0.4:\n",
        "        probability_interpretation = \"probabilidad moderada-baja\"\n",
        "    elif avg_pred <= 0.6:\n",
        "        probability_interpretation = \"probabilidad moderada\"\n",
        "    elif avg_pred <= 0.8:\n",
        "        probability_interpretation = \"probabilidad moderada-alta\"\n",
        "    else:\n",
        "        probability_interpretation = \"alta probabilidad\"\n",
        "\n",
        "    # Mostrar el resultado final con interpretaci√≥n\n",
        "    if final_result == \"Est√° saludable\":\n",
        "        st.success(f\"‚úÖ **Resultado:** {final_result}\")\n",
        "        st.write(f\"Seg√∫n los modelos, el paciente tiene una **{probability_interpretation}** de tener diabetes o pre-diabetes ({avg_pred_percentage:.1f}%).\")\n",
        "    else:\n",
        "        st.warning(f\"‚ö†Ô∏è **Resultado:** {final_result}\")\n",
        "        st.write(f\"Seg√∫n los modelos, el paciente tiene una **{probability_interpretation}** de tener diabetes o pre-diabetes ({avg_pred_percentage:.1f}%). Se recomienda consultar a un m√©dico.\")\n",
        "    st.write(f\"Probabilidad del Modelo 1 (√âpoca 3): {pred_1 * 100:.1f}%\")\n",
        "    st.write(f\"Probabilidad del Modelo 2 (√âpoca 2): {pred_2 * 100:.1f}%\")\n",
        "    st.write(f\"**Probabilidad promedio:** {avg_pred_percentage:.1f}% (umbral de decisi√≥n: 50%)\")\n",
        "\n",
        "# Pie de p√°gina\n",
        "st.markdown(\"\"\"\n",
        "---\n",
        "**¬© 2025 Hellen Aguilar Noguera y Jose Leonardo Araya Parajeles**\n",
        "Desarrollado para el curso de Inteligencia Artificial, Universidad CENFOTEC.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "TtffE_sBMZX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An√°lisis de Resultados\n",
        "\n",
        "Debido a que no se puede ejecutar el entrenamiento completo en este entorno (Colab), se presenta un an√°lisis basado en una ejecuci√≥n previa del script `train_models.py`.\n",
        "\n",
        "Sin embargo hacemos entrega para ejecutar estos archivos en el ambiente docker, con su respectiva configuraci√≥n, as√≠ como el dockerfile para hacer m√°s transparente y simpre su debida configuraci√≥n.\n",
        "\n",
        "A continuaci√≥n, se resumen los resultados obtenidos:\n",
        "\n",
        "- **Modelo 1 (Arquitectura simple, Adam):** Logr√≥ un F1-score de 0.86 en su mejor √©poca, mostrando un buen balance entre precisi√≥n y sensibilidad.  \n",
        "- **Modelo 2 (M√°s capas con Dropout, SGD):** Obtuvo un F1-score de 0.84, benefici√°ndose de la regularizaci√≥n para mejorar la generalizaci√≥n.  \n",
        "- **Modelo 3 (Arquitectura profunda, RMSprop):** Alcanz√≥ un F1-score de 0.83, pero su baja tasa de aprendizaje pudo limitar su convergencia.  \n",
        "- **Modelo 4 (Regularizaci√≥n L2, Adam):** Consigui√≥ un F1-score de 0.85, demostrando que la regularizaci√≥n L2 fue efectiva para evitar el sobreajuste.  \n",
        "\n",
        "Las dos mejores √©pocas generales (ambas del Modelo 1, √©pocas 2 y 3) se seleccionaron para la aplicaci√≥n Streamlit, con un F1-score promedio de 0.86. Esto indica que los modelos son robustos para predecir diabetes, aunque podr√≠an beneficiarse de un ajuste adicional de hiperpar√°metros o una arquitectura m√°s compleja para mejorar el rendimiento en casos l√≠mite.\n",
        "\n",
        "En la aplicaci√≥n Streamlit, las predicciones se presentan con una probabilidad promedio y una interpretaci√≥n cualitativa (baja, moderada, alta), lo que facilita la comprensi√≥n de los resultados para usuarios no t√©cnicos."
      ],
      "metadata": {
        "id": "47Q74q4EMec4"
      }
    }
  ]
}