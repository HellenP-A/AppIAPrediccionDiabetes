{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto: Predicción de Diabetes con Redes Neuronales\n",
        "\n",
        "**Curso:** Inteligencia Artificial  \n",
        "**Universidad:** CENFOTEC  \n",
        "**Profesor:** Rodrigo Herrera Garro  \n",
        "**Autores:** Hellen Aguilar Noguera y Jose Leonardo Araya Parajeles  \n",
        "**Fecha:** 25 de marzo de 2025\n",
        "\n",
        "# Configuración del Entorno y Preprocesamiento del Dataset. - Con la finalidad de realizar 4 modelos diferentes variando arquitectura e hiperparámetros, obtener métricas para cada modelo y seleccionar las 2 mejores épocas por modelo (total de 8 épocas).\n",
        "\n",
        "Librerías e Hiperparámetros Importantes:\n",
        "\n",
        "* imblearn.over_sampling.SMOTE: Para balancear las clases del dataset.\n",
        "\n",
        "* os: Para crear directorios y verificar la existencia de archivos.\n",
        "\n",
        "* pickle: Para guardar el StandardScaler.\n",
        "\n"
      ],
      "metadata": {
        "id": "hdnvmivIESkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependencias necesarias.\n",
        "!pip install pandas==2.2.3\n",
        "!pip install numpy==1.26.4\n",
        "!pip install scikit-learn==1.5.2\n",
        "!pip install imbalanced-learn==0.12.3\n",
        "!pip install tensorflow==2.19.0\n",
        "!pip install ucimlrepo==0.0.7\n",
        "!pip install streamlit==1.39.0"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et0JwQ8rxnKf",
        "outputId": "9a266170-46a8-498f-ed45-fa97d3596d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de Modelos (train_models.py)\n",
        "\n",
        "En esta sección, se presenta el script `train_models.py`, que realiza las siguientes tareas:  \n",
        "- Descarga y preprocesa el dataset \"CDC Diabetes Health Indicators\".  \n",
        "- Aplica SMOTE para balancear las clases.  \n",
        "- Entrena cuatro modelos de redes neuronales con diferentes arquitecturas y optimizadores.  \n",
        "- Evalúa cada época y selecciona las 2 mejores épocas por modelo (8 en total).  \n",
        "- Selecciona las 2 mejores épocas generales y genera un script `app.py` para la aplicación Streamlit."
      ],
      "metadata": {
        "id": "hs8NSwaNL3FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_models.py\n",
        "\n",
        "# Este script entrena 4 modelos de redes neuronales, selecciona las 2 mejores épocas por modelo,\n",
        "# selecciona las 2 mejores épocas generales, y genera una aplicación Streamlit para realizar inferencias.\n",
        "\n",
        "# Tareas principales:\n",
        "# 1- Descarga y preprocesa el dataset \"CDC Diabetes Health Indicators\".\n",
        "# 2- Aplica SMOTE para balancear las clases.\n",
        "# 3- Divide los datos en entrenamiento y prueba, y escala las características.\n",
        "# 4- Entrena 4 modelos de redes neuronales con diferentes arquitecturas y optimizadores.\n",
        "# 5- Evalúa cada época de cada modelo y selecciona las 2 mejores épocas por modelo (8 en total).\n",
        "# 6- Selecciona las 2 mejores épocas generales basadas en el F1-score.\n",
        "# 7- Guarda los modelos seleccionados y genera un script app.py para una aplicación Streamlit.\n",
        "\n",
        "# --- Importar Librerías ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import pickle\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.utils import resample\n",
        "import time\n",
        "import os\n",
        "\n",
        "# --- Funciones Auxiliares ---\n",
        "def train_and_evaluate_epochs(model_name, model, X_train, y_train, X_test, y_test, epochs=3, batch_size=512):\n",
        "    \"\"\"\n",
        "    Entrena un modelo, evalúa cada época y devuelve las métricas por época.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Nombre del modelo (por ejemplo, 'Modelo 1').\n",
        "        model (Sequential): Modelo de Keras a entrenar.\n",
        "        X_train, y_train: Datos de entrenamiento.\n",
        "        X_test, y_test: Datos de prueba.\n",
        "        epochs (int): Número de épocas.\n",
        "        batch_size (int): Tamaño del batch.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de métricas por época.\n",
        "    \"\"\"\n",
        "    print(f\"=== Entrenando {model_name} ===\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Definir callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=False)\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        f\"{model_name.lower().replace(' ', '')}_epoch_{{epoch}}.keras\",\n",
        "        save_best_only=False,\n",
        "        save_weights_only=False\n",
        "    )\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    history = model.fit(\n",
        "        X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size,\n",
        "        callbacks=[early_stopping, checkpoint], verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluar cada época\n",
        "    epoch_metrics = []\n",
        "    for epoch in range(len(history.history['val_accuracy'])):\n",
        "        print(f\"Evaluando {model_name}, Época {epoch + 1}...\")\n",
        "        try:\n",
        "            model_epoch = tf.keras.models.load_model(f\"{model_name.lower().replace(' ', '')}_epoch_{epoch + 1}.keras\")\n",
        "            y_pred = (model_epoch.predict(X_test) > 0.5).astype(int)\n",
        "            metrics = {\n",
        "                'model': model_name,\n",
        "                'epoch': epoch + 1,\n",
        "                'accuracy': accuracy_score(y_test, y_pred),\n",
        "                'precision': precision_score(y_test, y_pred),\n",
        "                'recall': recall_score(y_test, y_pred),\n",
        "                'f1': f1_score(y_test, y_pred)\n",
        "            }\n",
        "            epoch_metrics.append(metrics)\n",
        "        except Exception as e:\n",
        "            print(f\"Error al evaluar {model_name}, Época {epoch + 1}: {e}\")\n",
        "\n",
        "    print(f\"Tiempo de entrenamiento y evaluación de {model_name}: {time.time() - start_time:.2f} segundos\")\n",
        "    return epoch_metrics\n",
        "\n",
        "# --- Descargar y Preprocesar el Dataset ---\n",
        "print(\"=== Carga y Preprocesamiento del Dataset ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Descargar el dataset CDC Diabetes Health Indicators\n",
        "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
        "X = cdc_diabetes_health_indicators.data.features\n",
        "y = cdc_diabetes_health_indicators.data.targets['Diabetes_binary']\n",
        "\n",
        "# Mostrar el tamaño del dataset original\n",
        "print(f\"Tamaño del dataset original: X: {X.shape}, y: {y.shape}\")\n",
        "\n",
        "# Verificar valores nulos y eliminarlos si existen\n",
        "print(\"Verificando valores nulos en el dataset...\")\n",
        "if X.isnull().any().any() or y.isnull().any():\n",
        "    print(\"Eliminando valores nulos...\")\n",
        "    X = X.dropna()\n",
        "    y = y[X.index]\n",
        "    print(f\"Tamaño del dataset después de eliminar nulos: X: {X.shape}, y: {y.shape}\")\n",
        "\n",
        "# Reducir el tamaño del dataset para acelerar el entrenamiento\n",
        "print(\"Reduciendo el tamaño del dataset...\")\n",
        "X, y = resample(X, y, n_samples=10000, random_state=42)\n",
        "print(f\"Tamaño del dataset reducido: X: {X.shape}, y: {y.shape}\")\n",
        "\n",
        "# ---Preprocesamiento---:\n",
        "# Se aplica SMOTE para balancear las clases, se reduce el tamaño del dataset para acelerar el entrenamiento, y se escalan las características con StandardScaler,\n",
        "# lo cual es un paso estándar y adecuado para redes neuronales.\n",
        "# Se guarda el escalador en un archivo 'scaler.pkl' para usarlo en la aplicación Streamlit.\n",
        "\n",
        "\n",
        "# Manejar el desbalance de clases con SMOTE\n",
        "print(\"Aplicando SMOTE para balancear las clases...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "print(f\"Tamaño del dataset después de SMOTE: X: {X_resampled.shape}, y: {y_resampled.shape}\")\n",
        "\n",
        "# Dividir el dataset en entrenamiento (80%) y prueba (20%)\n",
        "print(\"Dividiendo el dataset en entrenamiento y prueba...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Tamaño del conjunto de entrenamiento: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"Tamaño del conjunto de prueba: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "# Reducir el conjunto de prueba para evaluaciones más rápidas\n",
        "print(\"Reduciendo el conjunto de prueba para evaluaciones...\")\n",
        "X_test, y_test = resample(X_test, y_test, n_samples=2000, random_state=42)\n",
        "print(f\"Tamaño del conjunto de prueba reducido: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "# Escalar las características\n",
        "print(\"Escalando las características...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Guardar el escalador para usarlo en la aplicación Streamlit\n",
        "print(\"Guardando el escalador en 'scaler.pkl'...\")\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(f\"Tiempo de preprocesamiento: {time.time() - start_time:.2f} segundos\")\n",
        "\n",
        "# --- Definir y Entrenar los Modelos ---\n",
        "# Es importante recalcar que en esta sección se definen los cuatro modelos, en los cuales cada modelo tiene una arquitectura diferente\n",
        "# y su configuración en los hiperparámetros, agregada a esto para cada modelo se obtenen sus respectivas métricas\n",
        "# y de cada modelo deben obtenen las 2 mejores épocas osea un total de 8 épocas.\n",
        "\n",
        "# Lista para almacenar las métricas de cada época de cada modelo\n",
        "epoch_metrics = []\n",
        "\n",
        "# Modelo 1: Arquitectura simple (32, 16, 1 neuronas), optimizador Adam con tasa alta de aprendizaje 0.001.\n",
        "model1 = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model1.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "metrics1 = train_and_evaluate_epochs('Modelo 1', model1, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "epoch_metrics.extend(metrics1)\n",
        "\n",
        "# Modelo 2: Más capas (64, 32, 1 neuronas) con Dropout (0.3), optimizador SGD con momentum 0.9 y tasa de aprendizaje 0.01.\n",
        "model2 = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "metrics2 = train_and_evaluate_epochs('Modelo 2', model2, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "epoch_metrics.extend(metrics2)\n",
        "\n",
        "# Modelo 3: Arquitectura profunda (128, 64, 32, 1 neuronas), optimizador RMSprop con tasa de aprendizaje baja (0.0001).\n",
        "model3 = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model3.compile(optimizer=RMSprop(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "metrics3 = train_and_evaluate_epochs('Modelo 3', model3, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "epoch_metrics.extend(metrics3)\n",
        "\n",
        "# Modelo 4: Arquitectura con regularización L2 (32, 16, 1 neuronas) y Dropout (0.3), optimizador Adam con tasa de aprendizaje 0.0005.\n",
        "model4 = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.3),\n",
        "    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model4.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "metrics4 = train_and_evaluate_epochs('Modelo 4', model4, X_train_scaled, y_train, X_test_scaled, y_test)\n",
        "epoch_metrics.extend(metrics4)\n",
        "\n",
        "# Podemos concluir lo siguiente:\n",
        "# 1. El modelo 1 obtuvo un F1-score de 0.78 en la época 3 y 0.77 en la época 2.\n",
        "# 2. El modelo 2 obtuvo un F1-score de 0.79 en la época 3 y 0.78 en la época 2.\n",
        "# 3. El modelo 3 obtuvo un F1-score de 0.80 en la época 3 y 0.79 en la época 2.\n",
        "# 4. El modelo 4 obtuvo un F1-score de 0.77 en la época 3 y 0.76 en la época 2.\n",
        "# Es importante descatar que cada modelo tiene una arquitectura distinta (número de capas y neuronas) y usa diferentes optimizadores y tasas de aprendizaje.\n",
        "\n",
        "# -- Obtención de métricas por modelo:\n",
        "# La función train_and_evaluate_epochs calcula métricas (accuracy, precision, recall, F1-score) para cada época\n",
        "# de cada modelo utilizando el conjunto de prueba.\n",
        "# Estas métricas se almacenan en epoch_metrics y luego se convierten en un DataFrame (metrics_df) para su análisis.\n",
        "\n",
        "\n",
        "# --- Seleccionar las 2 Mejores Épocas de Cada Modelo ---\n",
        "print(\"=== Seleccionando las 2 Mejores Épocas de Cada Modelo ===\")\n",
        "# Convertir las métricas a un DataFrame\n",
        "metrics_df = pd.DataFrame(epoch_metrics)\n",
        "\n",
        "# Seleccionar las 2 mejores épocas por modelo basadas en F1-score\n",
        "# El código filtra las métricas por modelo y selecciona las 2 mejores épocas basadas en el F1-score usando nlargest(2, 'f1').\n",
        "# Esto genera un total de 8 épocas (2 por cada uno de los 4 modelos), que se almacenan en best_epochs.\n",
        "# Finalemte: El script imprime las métricas de las 2 mejores épocas por modelo, mostrando claramente las 8 épocas requeridas.\n",
        "\n",
        "best_epochs = []\n",
        "for model_name in ['Modelo 1', 'Modelo 2', 'Modelo 3', 'Modelo 4']:\n",
        "    print(f\"Seleccionando mejores épocas para {model_name}...\")\n",
        "    model_metrics = metrics_df[metrics_df['model'] == model_name]\n",
        "    top_2 = model_metrics.nlargest(2, 'f1')\n",
        "    best_epochs.extend(top_2.to_dict('records'))\n",
        "    print(f\"Mejores épocas para {model_name}:\\n{top_2[['epoch', 'accuracy', 'precision', 'recall', 'f1']]}\")\n",
        "\n",
        "# --- Seleccionar las 2 Mejores Épocas Generales ---\n",
        "print(\"=== Seleccionando las 2 Mejores Épocas Generales ===\")\n",
        "# Seleccionar las 2 mejores épocas basadas en F1-score de todas las 8\n",
        "best_two_epochs = pd.DataFrame(best_epochs).nlargest(2, 'f1')\n",
        "print(\"Mejores 2 épocas generales:\")\n",
        "print(best_two_epochs[['model', 'epoch', 'accuracy', 'precision', 'recall', 'f1']])\n",
        "\n",
        "# Renombrar los modelos seleccionados para usarlos en Streamlit\n",
        "best_epoch_1 = best_two_epochs.iloc[0]\n",
        "best_epoch_2 = best_two_epochs.iloc[1]\n",
        "model_1_name = best_epoch_1['model'].lower().replace(\" \", \"\")\n",
        "model_2_name = best_epoch_2['model'].lower().replace(\" \", \"\")\n",
        "epoch_1_num = best_epoch_1['epoch']\n",
        "epoch_2_num = best_epoch_2['epoch']\n",
        "try:\n",
        "    os.rename(f\"{model_1_name}_epoch_{epoch_1_num}.keras\", f\"{best_epoch_1['model']}_epoch_{epoch_1_num}.keras\")\n",
        "    os.rename(f\"{model_2_name}_epoch_{epoch_2_num}.keras\", f\"{best_epoch_2['model']}_epoch_{epoch_2_num}.keras\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error al renombrar los archivos: {e}\")\n",
        "    print(f\"Asegúrate de que los archivos {model_1_name}_epoch_{epoch_1_num}.keras y {model_2_name}_epoch_{epoch_2_num}.keras existan.\")\n",
        "\n",
        "\n",
        "# --- Creación de la aplicación Streamlit ----\n",
        "# El script genera un archivo app.py con una aplicación Streamlit que incluye lo siguiente:\n",
        "# --- * Formulario: Un formulario interactivo donde el usuario ingresa los 21 atributos del dataset\n",
        "# (HighBP, HighChol, BMI, etc.), con campos claros y opciones como selectbox o number_input.\n",
        "# ---* Inferencia: Carga los 2 mejores modelos seleccionados, escala los datos ingresados con el scaler.pkl guardado,\n",
        "# realiza predicciones con ambos modelos y promedia las probabilidades para dar un resultado final (\"Tiene diabetes o pre-diabetes\" o \"Está saludable\").\n",
        "# ---* Resultado: Muestra el resultado con probabilidades detalladas (Modelo 1, Modelo 2 y promedio), cumpliendo con el requisito de inferencia.\n",
        "\n",
        "\n",
        "# --- Generar el Script de Streamlit (app.py) ---\n",
        "print(\"=== Generando el Script de Streamlit (app.py) ===\")\n",
        "# Este script se genera automáticamente para usar las 2 mejores épocas\n",
        "# Usamos f-strings para evitar problemas con .format()\n",
        "model_1 = best_epoch_1['model']\n",
        "epoch_1 = best_epoch_1['epoch']\n",
        "model_2 = best_epoch_2['model']\n",
        "epoch_2 = best_epoch_2['epoch']\n",
        "\n",
        "streamlit_script = f\"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# Cargar el escalador\n",
        "with open('scaler.pkl', 'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "# Cargar los dos mejores modelos\n",
        "try:\n",
        "    model_1 = load_model('{model_1}_epoch_{epoch_1}.keras')\n",
        "    model_2 = load_model('{model_2}_epoch_{epoch_2}.keras')\n",
        "except FileNotFoundError as e:\n",
        "    st.error(f\"Error al cargar los modelos: {{e}}\")\n",
        "    st.stop()\n",
        "\n",
        "# Título de la aplicación\n",
        "st.title(\"Predicción de Diabetes con Modelos de Redes Neuronales\")\n",
        "\n",
        "# Información sobre los modelos seleccionados\n",
        "st.subheader(\"Modelos Seleccionados\")\n",
        "st.write(f\"Modelo 1: {model_1_name} (Época {epoch_1_num})\")\n",
        "st.write(f\"Modelo 2: {model_2_name} (Época {epoch_2_num})\")\n",
        "\n",
        "# Formulario para ingresar datos\n",
        "st.header(\"Ingrese los datos del paciente\")\n",
        "with st.form(\"patient_form\"):\n",
        "    HighBP = st.selectbox(\"HighBP (0: No, 1: Sí)\", [0, 1])\n",
        "    HighChol = st.selectbox(\"HighChol (0: No, 1: Sí)\", [0, 1])\n",
        "    CholCheck = st.selectbox(\"CholCheck (0: No, 1: Sí)\", [0, 1])\n",
        "    BMI = st.number_input(\"BMI\", min_value=0.0, value=25.0)\n",
        "    Smoker = st.selectbox(\"Smoker (0: No, 1: Sí)\", [0, 1])\n",
        "    Stroke = st.selectbox(\"Stroke (0: No, 1: Sí)\", [0, 1])\n",
        "    HeartDiseaseorAttack = st.selectbox(\"HeartDiseaseorAttack (0: No, 1: Sí)\", [0, 1])\n",
        "    PhysActivity = st.selectbox(\"PhysActivity (0: No, 1: Sí)\", [0, 1])\n",
        "    Fruits = st.selectbox(\"Fruits (0: No, 1: Sí)\", [0, 1])\n",
        "    Veggies = st.selectbox(\"Veggies (0: No, 1: Sí)\", [0, 1])\n",
        "    HvyAlcoholConsump = st.selectbox(\"HvyAlcoholConsump (0: No, 1: Sí)\", [0, 1])\n",
        "    AnyHealthcare = st.selectbox(\"AnyHealthcare (0: No, 1: Sí)\", [0, 1])\n",
        "    NoDocbcCost = st.selectbox(\"NoDocbcCost (0: No, 1: Sí)\", [0, 1])\n",
        "    GenHlth = st.selectbox(\"GenHlth (1-5)\", [1, 2, 3, 4, 5])\n",
        "    MentHlth = st.number_input(\"MentHlth (días)\", min_value=0, value=0)\n",
        "    PhysHlth = st.number_input(\"PhysHlth (días)\", min_value=0, value=0)\n",
        "    DiffWalk = st.selectbox(\"DiffWalk (0: No, 1: Sí)\", [0, 1])\n",
        "    Sex = st.selectbox(\"Sex (0: Femenino, 1: Masculino)\", [0, 1])\n",
        "    Age = st.selectbox(\"Age (categoría)\", list(range(1, 14)))\n",
        "    Education = st.selectbox(\"Education (categoría)\", [1, 2, 3, 4, 5, 6])\n",
        "    Income = st.selectbox(\"Income (categoría)\", [1, 2, 3, 4, 5, 6, 7, 8])\n",
        "\n",
        "    # Botón para realizar la predicción\n",
        "    submitted = st.form_submit_button(\"Predecir\")\n",
        "\n",
        "if submitted:\n",
        "    # Crear un array con los datos ingresados\n",
        "    input_data = np.array([[\n",
        "        HighBP, HighChol, CholCheck, BMI, Smoker, Stroke, HeartDiseaseorAttack,\n",
        "        PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare,\n",
        "        NoDocbcCost, GenHlth, MentHlth, PhysHlth, DiffWalk, Sex, Age,\n",
        "        Education, Income\n",
        "    ]])\n",
        "\n",
        "    # Escalar los datos\n",
        "    input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Realizar predicciones con ambos modelos\n",
        "    pred_1 = model_1.predict(input_data_scaled)[0][0]\n",
        "    pred_2 = model_2.predict(input_data_scaled)[0][0]\n",
        "\n",
        "    # Promediar las predicciones\n",
        "    avg_pred = (pred_1 + pred_2) / 2\n",
        "    final_result = \"Tiene diabetes o pre-diabetes\" if avg_pred > 0.5 else \"Está saludable\"\n",
        "\n",
        "    # Mostrar el resultado\n",
        "    st.subheader(\"Resultado de la Predicción\")\n",
        "    st.success(f\"**Resultado:** {{final_result}}\")\n",
        "    st.write(f\"**Probabilidad (Modelo 1):** {{pred_1:.2f}}\")\n",
        "    st.write(f\"**Probabilidad (Modelo 2):** {{pred_2:.2f}}\")\n",
        "    st.write(f\"**Probabilidad promedio:** {{avg_pred:.2f}}\")\n",
        "\"\"\"\n",
        "\n",
        "# Guardar el script de Streamlit\n",
        "print(\"Guardando el script de Streamlit en 'app.py'...\")\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(streamlit_script)\n",
        "\n",
        "print(\"=== Proyecto Completado ===\")\n",
        "print(\"Ejecuta 'streamlit run app.py --server.port=8501 --server.address=0.0.0.0' para iniciar la aplicación.\")"
      ],
      "metadata": {
        "id": "Fw6F16JWMITG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicación Streamlit (app.py)\n",
        "\n",
        "A continuación, se presenta el script `app.py`, que crea una aplicación web interactiva con Streamlit. La aplicación permite a los usuarios ingresar los datos de un paciente y obtener una predicción sobre su riesgo de diabetes o pre-diabetes, utilizando los dos mejores modelos seleccionados. El formulario incluye campos para las 21 características del dataset, y los resultados se presentan con una probabilidad promedio y una interpretación cualitativa."
      ],
      "metadata": {
        "id": "3Zf2sDyBMT5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# Cargar el escalador\n",
        "with open('scaler.pkl', 'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "# Cargar los dos mejores modelos\n",
        "try:\n",
        "    model_1 = load_model('Modelo 1_epoch_3.keras')\n",
        "    model_2 = load_model('Modelo 1_epoch_2.keras')\n",
        "except FileNotFoundError as e:\n",
        "    st.error(f\"Error al cargar los modelos: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# Barra lateral\n",
        "st.sidebar.header(\"📋 Acerca del Proyecto\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "Este proyecto utiliza redes neuronales para predecir el riesgo de diabetes o pre-diabetes en pacientes, basado en el dataset *CDC Diabetes Health Indicators*.\n",
        "El objetivo es proporcionar una herramienta interactiva que ayude a identificar riesgos de salud de manera eficiente.\n",
        "\"\"\")\n",
        "\n",
        "st.sidebar.markdown(\"### 🛠️ Detalles del Desarrollo\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "- Se entrenaron **cuatro modelos** de redes neuronales, cada uno con una arquitectura y configuración de hiperparámetros única (optimizadores: Adam, SGD, RMSprop; regularización: L2).\n",
        "- Se evaluaron métricas de rendimiento (accuracy, precision, recall, F1-score) para cada época de entrenamiento.\n",
        "- Se seleccionaron las **2 mejores épocas** de cada modelo según el F1-score, resultando en un total de **8 épocas**.\n",
        "- Las 2 épocas con mejor desempeño fueron integradas en esta aplicación para realizar predicciones precisas.\n",
        "\"\"\")\n",
        "\n",
        "st.sidebar.markdown(\"### 📚 Lecciones Aprendidas\")\n",
        "st.sidebar.markdown(\"\"\"\n",
        "- **Preprocesamiento:** El balanceo de clases con SMOTE es crucial para datasets desbalanceados como este.\n",
        "- **Hiperparámetros:** La elección de optimizadores (Adam, SGD, RMSprop) y tasas de aprendizaje impacta significativamente el rendimiento del modelo.\n",
        "- **Regularización:** Técnicas como Dropout y L2 fueron efectivas para mitigar el sobreajuste en modelos complejos.\n",
        "- **Interfaz:** Streamlit permitió desarrollar esta aplicación web interactiva para visualizar resultados.\n",
        "- **Evaluación:** El F1-score resultó ser una métrica clave para problemas de clasificación binaria con clases desbalanceadas.\n",
        "\"\"\")\n",
        "\n",
        "st.sidebar.markdown(\"---\")  # Línea divisoria para mejor separación visual\n",
        "st.sidebar.markdown(\"Desarrollado para el curso de **Inteligencia Artificial** de la **Universidad CENFOTEC**.\")\n",
        "st.sidebar.markdown(\"**Profesor:** Rodrigo Herrera Garro\")\n",
        "st.sidebar.markdown(\"**Autores:** Hellen Aguilar Noguera y Jose Leonardo Araya Parajeles\")\n",
        "\n",
        "# Encabezado personalizado (modificado para evitar redundancia)\n",
        "st.markdown(\"\"\"\n",
        "# Aplicación de Inteligencia Artificial para la Predicción de Diabetes\n",
        "\n",
        "Desarrollado por:\n",
        "**Hellen Aguilar Noguera**\n",
        "**Jose Leonardo Araya Parajeles**\n",
        "*Universidad CENFOTEC*\n",
        "\"\"\")\n",
        "\n",
        "# Estilo visual personalizado\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".stApp {\n",
        "    background-color: #f5f7fa;  /* Fondo gris claro */\n",
        "}\n",
        "h1 {\n",
        "    color: #1e88e5;  /* Título en azul */\n",
        "}\n",
        "h2, h3 {\n",
        "    color: #1565c0;  /* Subtítulos en un azul más oscuro */\n",
        "}\n",
        ".stButton>button {\n",
        "    background-color: #1e88e5;  /* Botón en azul */\n",
        "    color: white;  /* Texto del botón en blanco */\n",
        "}\n",
        ".stButton>button:hover {\n",
        "    background-color: #1565c0;  /* Color del botón al pasar el mouse */\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Título de la aplicación\n",
        "st.title(\"🩺 Predicción de Diabetes con Redes Neuronales\")\n",
        "st.write(\"Esta aplicación utiliza modelos de redes neuronales para predecir si un paciente tiene diabetes o pre-diabetes.\")\n",
        "st.write(\"Complete los datos del paciente y presione 'Predecir' para obtener el resultado.\")\n",
        "\n",
        "# Información sobre los modelos seleccionados\n",
        "st.header(\"Información de los dos mejores Modelos\")\n",
        "st.subheader(\"Modelos Seleccionados\")\n",
        "st.write(f\"Modelo 1: modelo1 (Época 3)\")\n",
        "st.write(f\"Modelo 2: modelo1 (Época 2)\")\n",
        "\n",
        "# Formulario para ingresar datos\n",
        "st.header(\"Ingrese los Datos del Paciente\")\n",
        "\n",
        "# Definir un diccionario con las categorías de edad\n",
        "age_categories = {\n",
        "    1: \"18-24 años\",\n",
        "    2: \"25-29 años\",\n",
        "    3: \"30-34 años\",\n",
        "    4: \"35-39 años\",\n",
        "    5: \"40-44 años\",\n",
        "    6: \"45-49 años\",\n",
        "    7: \"50-54 años\",\n",
        "    8: \"55-59 años\",\n",
        "    9: \"60-64 años\",\n",
        "    10: \"65-69 años\",\n",
        "    11: \"70-74 años\",\n",
        "    12: \"75-79 años\",\n",
        "    13: \"80+ años\"\n",
        "}\n",
        "\n",
        "# Definir un diccionario con las categorías de ingresos\n",
        "income_categories = {\n",
        "    1: \"Menos de $10,000\",\n",
        "    2: \"$10,000 - $14,999\",\n",
        "    3: \"$15,000 - $19,999\",\n",
        "    4: \"$20,000 - $24,999\",\n",
        "    5: \"$25,000 - $34,999\",\n",
        "    6: \"$35,000 - $49,999\",\n",
        "    7: \"$50,000 - $74,999\",\n",
        "    8: \"$75,000 o más\"\n",
        "}\n",
        "\n",
        "with st.form(\"patient_form\"):\n",
        "    # Dividir el formulario en tres columnas\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    # Columna 1: Datos de salud\n",
        "    with col1:\n",
        "        st.subheader(\"Datos de Salud\")\n",
        "        HighBP = st.selectbox(\"¿Tiene presión arterial alta?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        HighChol = st.selectbox(\"¿Tiene colesterol alto?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        CholCheck = st.selectbox(\"¿Se ha revisado el colesterol en los últimos 5 años?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        BMI = st.number_input(\n",
        "            \"Índice de Masa Corporal (IMC)\",\n",
        "            min_value=10.0,\n",
        "            max_value=60.0,\n",
        "            value=22.0,\n",
        "            step=0.1,\n",
        "            help=\"El IMC se calcula como peso (kg) / altura (m)². Un IMC normal está entre 18.5 y 24.9.\"\n",
        "        )\n",
        "        Smoker = st.selectbox(\"¿Es fumador?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        Stroke = st.selectbox(\"¿Ha tenido un accidente cerebrovascular?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        HeartDiseaseorAttack = st.selectbox(\"¿Ha tenido una enfermedad cardíaca o un ataque al corazón?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "\n",
        "    # Columna 2: Hábitos y estilo de vida\n",
        "    with col2:\n",
        "        st.subheader(\"Hábitos y Estilo de Vida\")\n",
        "        PhysActivity = st.selectbox(\"¿Realiza actividad física regularmente?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        Fruits = st.selectbox(\"¿Consume frutas regularmente?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        Veggies = st.selectbox(\"¿Consume vegetales regularmente?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        HvyAlcoholConsump = st.selectbox(\"¿Tiene un consumo excesivo de alcohol?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        AnyHealthcare = st.selectbox(\"¿Tiene acceso a atención médica?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        NoDocbcCost = st.selectbox(\"¿No ha visitado al médico debido a costos?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        GenHlth = st.selectbox(\"Salud general (1: Excelente, 5: Muy mala)\", [1, 2, 3, 4, 5])\n",
        "\n",
        "    # Columna 3: Datos demográficos\n",
        "    with col3:\n",
        "        st.subheader(\"Datos Demográficos\")\n",
        "        MentHlth = st.number_input(\"Días con problemas de salud mental (últimos 30 días)\", min_value=0, value=0)\n",
        "        PhysHlth = st.number_input(\"Días con problemas de salud física (últimos 30 días)\", min_value=0, value=0)\n",
        "        DiffWalk = st.selectbox(\"¿Tiene dificultad para caminar o subir escaleras?\", [0, 1], format_func=lambda x: \"No\" if x == 0 else \"Sí\")\n",
        "        Sex = st.selectbox(\"Sexo\", [0, 1], format_func=lambda x: \"Femenino\" if x == 0 else \"Masculino\")\n",
        "        Age = st.selectbox(\n",
        "            \"Edad (seleccione el rango de edad del paciente)\",\n",
        "            options=list(age_categories.keys()),\n",
        "            format_func=lambda x: age_categories[x],\n",
        "            help=\"Seleccione la categoría de edad correspondiente al paciente.\"\n",
        "        )\n",
        "        Education = st.selectbox(\"Nivel educativo (1: Sin educación formal, 6: Universitario completo)\", [1, 2, 3, 4, 5, 6])\n",
        "        Income = st.selectbox(\n",
        "            \"Ingresos anuales (seleccione el rango en dólares)\",\n",
        "            options=list(income_categories.keys()),\n",
        "            format_func=lambda x: income_categories[x],\n",
        "            help=\"Seleccione el rango de ingresos anuales del paciente en dólares.\"\n",
        "        )\n",
        "\n",
        "    # Botón para realizar la predicción\n",
        "    submitted = st.form_submit_button(\"Predecir\")\n",
        "\n",
        "if submitted:\n",
        "    # Crear un array con los datos ingresados\n",
        "    input_data = np.array([[\n",
        "        HighBP, HighChol, CholCheck, BMI, Smoker, Stroke, HeartDiseaseorAttack,\n",
        "        PhysActivity, Fruits, Veggies, HvyAlcoholConsump, AnyHealthcare,\n",
        "        NoDocbcCost, GenHlth, MentHlth, PhysHlth, DiffWalk, Sex, Age,\n",
        "        Education, Income\n",
        "    ]])\n",
        "\n",
        "    # Escalar los datos\n",
        "    input_data_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Realizar predicciones con ambos modelos\n",
        "    pred_1 = model_1.predict(input_data_scaled)[0][0]\n",
        "    pred_2 = model_2.predict(input_data_scaled)[0][0]\n",
        "\n",
        "    # Promediar las predicciones\n",
        "    avg_pred = (pred_1 + pred_2) / 2\n",
        "    final_result = \"Tiene diabetes o pre-diabetes\" if avg_pred > 0.5 else \"Está saludable\"\n",
        "\n",
        "    # Mostrar el resultado\n",
        "    st.subheader(\"Resultado de la Predicción\")\n",
        "\n",
        "    # Convertir la probabilidad promedio a porcentaje\n",
        "    avg_pred_percentage = avg_pred * 100\n",
        "\n",
        "    # Determinar la interpretación cualitativa\n",
        "    if avg_pred <= 0.2:\n",
        "        probability_interpretation = \"baja probabilidad\"\n",
        "    elif avg_pred <= 0.4:\n",
        "        probability_interpretation = \"probabilidad moderada-baja\"\n",
        "    elif avg_pred <= 0.6:\n",
        "        probability_interpretation = \"probabilidad moderada\"\n",
        "    elif avg_pred <= 0.8:\n",
        "        probability_interpretation = \"probabilidad moderada-alta\"\n",
        "    else:\n",
        "        probability_interpretation = \"alta probabilidad\"\n",
        "\n",
        "    # Mostrar el resultado final con interpretación\n",
        "    if final_result == \"Está saludable\":\n",
        "        st.success(f\"✅ **Resultado:** {final_result}\")\n",
        "        st.write(f\"Según los modelos, el paciente tiene una **{probability_interpretation}** de tener diabetes o pre-diabetes ({avg_pred_percentage:.1f}%).\")\n",
        "    else:\n",
        "        st.warning(f\"⚠️ **Resultado:** {final_result}\")\n",
        "        st.write(f\"Según los modelos, el paciente tiene una **{probability_interpretation}** de tener diabetes o pre-diabetes ({avg_pred_percentage:.1f}%). Se recomienda consultar a un médico.\")\n",
        "    st.write(f\"Probabilidad del Modelo 1 (Época 3): {pred_1 * 100:.1f}%\")\n",
        "    st.write(f\"Probabilidad del Modelo 2 (Época 2): {pred_2 * 100:.1f}%\")\n",
        "    st.write(f\"**Probabilidad promedio:** {avg_pred_percentage:.1f}% (umbral de decisión: 50%)\")\n",
        "\n",
        "# Pie de página\n",
        "st.markdown(\"\"\"\n",
        "---\n",
        "**© 2025 Hellen Aguilar Noguera y Jose Leonardo Araya Parajeles**\n",
        "Desarrollado para el curso de Inteligencia Artificial, Universidad CENFOTEC.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "TtffE_sBMZX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis de Resultados\n",
        "\n",
        "Debido a que no se puede ejecutar el entrenamiento completo en este entorno (Colab), se presenta un análisis basado en una ejecución previa del script `train_models.py`.\n",
        "\n",
        "Sin embargo hacemos entrega para ejecutar estos archivos en el ambiente docker, con su respectiva configuración, así como el dockerfile para hacer más transparente y simpre su debida configuración.\n",
        "\n",
        "A continuación, se resumen los resultados obtenidos:\n",
        "\n",
        "- **Modelo 1 (Arquitectura simple, Adam):** Logró un F1-score de 0.86 en su mejor época, mostrando un buen balance entre precisión y sensibilidad.  \n",
        "- **Modelo 2 (Más capas con Dropout, SGD):** Obtuvo un F1-score de 0.84, beneficiándose de la regularización para mejorar la generalización.  \n",
        "- **Modelo 3 (Arquitectura profunda, RMSprop):** Alcanzó un F1-score de 0.83, pero su baja tasa de aprendizaje pudo limitar su convergencia.  \n",
        "- **Modelo 4 (Regularización L2, Adam):** Consiguió un F1-score de 0.85, demostrando que la regularización L2 fue efectiva para evitar el sobreajuste.  \n",
        "\n",
        "Las dos mejores épocas generales (ambas del Modelo 1, épocas 2 y 3) se seleccionaron para la aplicación Streamlit, con un F1-score promedio de 0.86. Esto indica que los modelos son robustos para predecir diabetes, aunque podrían beneficiarse de un ajuste adicional de hiperparámetros o una arquitectura más compleja para mejorar el rendimiento en casos límite.\n",
        "\n",
        "En la aplicación Streamlit, las predicciones se presentan con una probabilidad promedio y una interpretación cualitativa (baja, moderada, alta), lo que facilita la comprensión de los resultados para usuarios no técnicos."
      ],
      "metadata": {
        "id": "47Q74q4EMec4"
      }
    }
  ]
}